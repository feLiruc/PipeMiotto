# PipeMiotto - Sistema de Webhooks com Kafka

Sistema robusto de processamento de webhooks usando Apache Kafka para garantir entrega e processamento confiÃ¡vel.

## ğŸ“ Estrutura do Projeto

```
PipeMiotto/
â”œâ”€â”€ index.js          # API principal (webhook receiver)
â”œâ”€â”€ consumer.js       # Consumer Kafka (processa mensagens)
â”œâ”€â”€ kafka.js          # ServiÃ§o Kafka (producer/consumer)
â”œâ”€â”€ db.js             # ConexÃ£o e operaÃ§Ãµes do banco
â”œâ”€â”€ manage.sh         # Script de gerenciamento
â”œâ”€â”€ config.json       # ConfiguraÃ§Ãµes das tabelas
â”œâ”€â”€ package.json      # DependÃªncias Node.js
â””â”€â”€ .env              # VariÃ¡veis de ambiente
```

## ğŸš€ InstalaÃ§Ã£o e ConfiguraÃ§Ã£o

### 1. Instalar dependÃªncias
```bash
npm install
```

### 2. Configurar variÃ¡veis de ambiente
```bash
cp .env.example .env
# Editar .env com suas configuraÃ§Ãµes
```

### 3. Inicializar banco de dados
```bash
npm start -- --clean  # Primeira vez (limpa tabelas)
```

## ğŸ”§ Como Usar

### Usando o script de gerenciamento (Recomendado)
```bash
# Dar permissÃ£o de execuÃ§Ã£o
chmod +x manage.sh

# Iniciar sistema completo
./manage.sh start

# Ver status
./manage.sh status

# Ver logs em tempo real
./manage.sh logs

# Parar sistema
./manage.sh stop

# Reiniciar
./manage.sh restart
```

### Comandos manuais
```bash
# Iniciar apenas a API
npm start

# Iniciar apenas o Consumer
npm run consumer
```

## ğŸ“Š Fluxo de Funcionamento

1. **Webhook recebido** â†’ API (index.js)
2. **Dados enviados** â†’ Kafka Topic (webhook-events)
3. **Consumer processa** â†’ Salva no banco (consumer.js)
4. **Em caso de erro** â†’ Retry automÃ¡tico ou DLQ

## ğŸ” Monitoramento

### Verificar tÃ³picos Kafka
```bash
cd /opt/kafka
bin/kafka-topics.sh --list --bootstrap-server localhost:9092
```

### Ver mensagens em um tÃ³pico
```bash
bin/kafka-console-consumer.sh --topic webhook-events --bootstrap-server localhost:9092 --from-beginning
```

### Verificar Dead Letter Queue
```bash
bin/kafka-console-consumer.sh --topic webhook-events-dlq --bootstrap-server localhost:9092 --from-beginning
```

## ğŸ› ï¸ ConfiguraÃ§Ãµes AvanÃ§adas

### Configurar retenÃ§Ã£o de mensagens
```bash
bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type topics --entity-name webhook-events --alter --add-config retention.ms=604800000
```

### Aumentar partiÃ§Ãµes
```bash
bin/kafka-topics.sh --bootstrap-server localhost:9092 --alter --topic webhook-events --partitions 6
```

## ğŸš¨ Troubleshooting

### Kafka nÃ£o inicia
```bash
sudo systemctl status kafka
sudo journalctl -u kafka -f
```

### Consumer nÃ£o processa mensagens
1. Verificar se o tÃ³pico existe
2. Verificar conexÃ£o com banco
3. Ver logs: `tail -f consumer.log`

### API retorna erro 500
1. Verificar conexÃ£o com Kafka
2. Verificar variÃ¡veis de ambiente
3. Ver logs: `tail -f api.log`

## ğŸ“ˆ BenefÃ­cios da ImplementaÃ§Ã£o

- âœ… **Garantia de entrega**: Kafka persiste mensagens
- âœ… **Processamento assÃ­ncrono**: Webhook responde rapidamente
- âœ… **Retry automÃ¡tico**: Falhas sÃ£o processadas novamente
- âœ… **Dead Letter Queue**: Mensagens problemÃ¡ticas sÃ£o isoladas
- âœ… **Escalabilidade**: FÃ¡cil adicionar mais consumers
- âœ… **Monitoramento**: Logs detalhados de todo o processo